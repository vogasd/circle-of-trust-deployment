apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: circle-ollama
  namespace: circle-prod
  labels:
    app: circle-ollama
    component: llm
spec:
  replicas: 1
  serviceName: circle-ollama
  selector:
    matchLabels:
      app: circle-ollama
  template:
    metadata:
      labels:
        app: circle-ollama
        component: llm
    spec:
      affinity:
        nodeAffinity:
          requiredDuringSchedulingIgnoredDuringExecution:
            nodeSelectorTerms:
              - matchExpressions:
                  - key: agentpool
                    operator: In
                    values:
                      - gpunodepool
        podAntiAffinity:
          preferredDuringSchedulingIgnoredDuringExecution:
            - weight: 100
              podAffinityTerm:
                labelSelector:
                  matchExpressions:
                    - key: app
                      operator: In
                      values:
                        - circle-ollama
                topologyKey: topology.kubernetes.io/zone
      securityContext:
        runAsNonRoot: true
        runAsUser: 1000
        fsGroup: 1000
      initContainers:
        - name: model-downloader
          image: ollama
          command:
            - /bin/sh
            - -c
            - |
              if [ ! -f /root/.ollama/models/manifests/registry.ollama.ai/library/llama2/latest ]; then
                ollama pull llama2
              fi
          volumeMounts:
            - name: ollama-data
              mountPath: /root/.ollama
      containers:
        - name: ollama
          image: ollama
          ports:
            - name: http
              containerPort: 11434
              protocol: TCP
          env:
            - name: OLLAMA_HOST
              value: "0.0.0.0:11434"
            - name: OLLAMA_MODELS
              value: "/root/.ollama/models"
          resources:
            requests:
              cpu: 2000m
              memory: 8Gi
              nvidia.com/gpu: 1
            limits:
              cpu: 4000m
              memory: 16Gi
              nvidia.com/gpu: 1
          livenessProbe:
            httpGet:
              path: /
              port: http
            initialDelaySeconds: 60
            periodSeconds: 30
            timeoutSeconds: 10
            failureThreshold: 3
          readinessProbe:
            httpGet:
              path: /
              port: http
            initialDelaySeconds: 30
            periodSeconds: 10
            timeoutSeconds: 5
            failureThreshold: 3
          startupProbe:
            httpGet:
              path: /
              port: http
            initialDelaySeconds: 0
            periodSeconds: 10
            timeoutSeconds: 5
            failureThreshold: 60
          securityContext:
            allowPrivilegeEscalation: false
            runAsNonRoot: true
            runAsUser: 1000
            capabilities:
              drop:
                - ALL
          volumeMounts:
            - name: ollama-data
              mountPath: /root/.ollama
  volumeClaimTemplates:
    - metadata:
        name: ollama-data
      spec:
        accessModes:
          - ReadWriteOnce
        storageClassName: managed-premium
        resources:
          requests:
            storage: 200Gi
